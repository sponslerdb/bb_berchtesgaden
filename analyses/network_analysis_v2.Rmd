---
title: "network_analysis"
output: html_document
---

### Prepare environment
```{r setup, include=FALSE}
library(bipartite)
library(mgcv)
library(mgcViz)
library(piecewiseSEM)
library(GGally)
library(tidyverse)
library(lubridate)
```

### Define functions
#### Bootstrapped network analysis: *boot_net* function bootstraps networks by iteratively subsampling more frequently sampled networks to match the transect count of the least frequently sampled one
```{r, include=FALSE}
#####################################
######## species level ##############
#####################################
boot_net_sp <- function(net, n, iter) {
  
  out <- data.frame()
  
  t_filter <- net %>%
    dplyr::select(site, date, year) %>%
    unique() %>%
    group_by(site, year) %>%
    mutate(transects = n()) %>%
    filter(transects >= n)
  
  for(i in 1:iter) {
    temp <- net %>%
      semi_join(t_filter) %>%
      dplyr::select(site, date, year) %>%
      unique() %>%
      group_by(site, year) %>%
      sample_n(n) %>%
      left_join(net) %>%
      group_by(site, year, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
      summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
      unite(webID, c(site, year), sep = "_") %>%
      ungroup() %>%
      dplyr::select(higher = bb.sp, lower = plant.sp, webID, freq) %>% # rename columns to match bipartite's expectations
      data.frame() %>% # convert to data frame
      frame2webs() %>% # convert to to bipartite web
      #map(specieslevel, level = "higher", index = "d") %>%
      map(specieslevel, level = "higher", index = c("d", "resource range", "degree", "partner diversity")) %>%
      map(rownames_to_column) %>%
      map(as_tibble) %>%
      bind_rows(.id = "site_year") %>% # Collapse list into big data frame
      rename(bb.sp = rowname) %>%
      mutate(iteration = rep(i, n()))
    
    out <- bind_rows(out, temp)
  } 
  out <- out %>%
    gather(metric, value, -c(bb.sp, site_year, iteration)) %>% # get mean value across iterations for each metric
    group_by(bb.sp, site_year, metric) %>%
    summarize(value = mean(value)) %>%
    separate(site_year, c("site", "year"), sep = "_") 
}

#####################################
######## network level ##############
#####################################
boot_net <- function(net, n, iter) {
  
  out <- data.frame()
  
  t_filter <- net %>%
    dplyr::select(site, date, year) %>%
    unique() %>%
    group_by(site, year) %>%
    mutate(transects = n()) %>%
    filter(transects >= n)
  
  for(i in 1:iter) {
    temp <- net %>%
      semi_join(t_filter) %>%
      dplyr::select(site, date, year) %>%
      unique() %>%
      group_by(site, year) %>%
      sample_n(n) %>%
      left_join(net) %>%
      group_by(site, year, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
      summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
      group_by(site, year) %>%
      unite(webID, c(site, year), sep = "_") %>%
      #filter(length(unique(bb.sp)) > 1 & length(unique(plant.sp)) > 1) %>%
      ungroup() %>%
      dplyr::select(higher = bb.sp, lower = plant.sp, webID, freq) %>% # rename columns to match bipartite's expectations
      data.frame() %>% # convert to data frame
      frame2webs() %>% # convert to to bipartite web
      map(networklevel, level = "higher", weighted = TRUE, index = c("niche overlap", "web asymmetry", "weighted NODF", "partner diversity", "C score")) %>% # We probably care mainly about the BB level of the network
      data.frame() %>%
      t() %>%
      data.frame() %>%
      rownames_to_column() %>%
      dplyr::select(site_year = rowname, everything()) %>%
      as_tibble() %>%
      mutate(iteration = rep(i, n()))
    
    out <- bind_rows(out, temp)
  } 
  out <- out  %>%
      gather(metric, value, -c(site_year, iteration)) %>% # get mean value across iterations for each metric
      group_by(site_year, metric) %>%
      summarize(value = mean(value)) %>%
      separate(site_year, c("site", "year"), sep = "_") 
}


##################################################
######## network level by site-date ##############
##################################################
site_date_net <- function(net, min_higher, min_lower) {
  
  size_filter <- net %>%
    group_by(site, date) %>%
    summarize(higher.species = length(unique(bb.sp)),
              lower.species = length(unique(plant.sp))) %>%
    filter(higher.species >= min_higher & lower.species >= min_lower)
  
  out <- net %>%
    semi_join(size_filter, by = c("site", "date")) %>%
    group_by(site, date, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
    summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
    unite(webID, c(site, date), sep = "_") %>%
    ungroup() %>%
    dplyr::select(higher = bb.sp, lower = plant.sp, webID, freq) %>% # rename columns to match bipartite's expectations
    data.frame() %>% # convert to data frame
    frame2webs() %>% # convert to to bipartite web
    map(networklevel, level = "higher", weighted = TRUE, 
        index = c("weighted NODF", "niche overlap", 
                  "C score", "generality", "web asymmetry", 
                  "weighted connectance")) %>% # We probably care mainly about the BB level of the network
    data.frame() %>%
    t() %>%
    data.frame() %>%
    rownames_to_column() %>%
    dplyr::select(site_date = rowname, everything()) %>%
    as_tibble() %>%
    separate(site_date, c("site", "date"), sep = "_")
}
```

### Load site data
```{r, include=FALSE}
site_data <- read_csv("../processed_data/site_data.csv") %>%
  dplyr::select(-c(slope.calc, slope.est, elev.min, elev.max, temp.mean)) %>% # drop these variables
  mutate(elev.class = factor(elev.class, levels = c("oben", "mitte", "unten")),
         elev.class2 = factor(elev.class2, levels = c("high", "mid", "low"))) # turn elav.class into an ordered factor
```

### Climate data
```{r, include=FALSE}
gdd <- read_csv("../processed_data/climate.csv") %>%
  mutate(year = factor(year)) %>%
  dplyr::select(site, date, gdd.cum)
```

### Load network and survey data
```{r, include=FALSE}
net <- read_csv("../processed_data/network.csv") %>%
  unite(site.year, site, year, sep = "_", remove = FALSE) %>% # create site.year field that can later be split back up
  mutate(year = factor(year)) %>% # convert year to factor
  left_join(site_data, by = "site") %>%
  left_join(gdd, by = c("site", "date")) %>%
  ungroup() %>%
  arrange(site, date)

# Yearly subsets
net_2012 <- filter(net, year == "2012")
net_2011 <- filter(net, year == "2011")
net_2010 <- filter(net, year == "2010")

# Floral survey
survey <- read_csv("../processed_data/floral_survey.csv") %>%
  semi_join(net, by = "plant.sp") %>% # Consider only plants visited (anytime anywhere, not specifically for a given site*date)
  dplyr::select(site, date, plant.sp, flower.cover)
```

### Analyze sampling patterns
```{r}
samples <- net %>%
  mutate(yday = yday(date)) %>%
  group_by(site, year, yday, gdd.cum, elev.mean) %>%
  summarize(obs = n())

ggplot(samples, aes(yday, elev.mean, size = obs)) +
  geom_point(alpha = 0.25) + 
  facet_wrap(~year)

ggplot(samples, aes(gdd.cum, elev.mean, size = obs)) +
  geom_point(alpha = 0.25) + 
  facet_wrap(~year)

### Can we make an argument for salvaging individual years, or parts of year?
#### 2011
ggplot(filter(samples, year == 2011), aes(elev.mean, obs)) +
  geom_point() +
  geom_smooth()

### How evenly is the presence of species distributed across samples
bb_abund_sp <- net %>%
  group_by(site, dayofyear, elev.mean, year, bb.sp) %>%
  summarize(abund = n())

ggplot(filter(bb_abund_sp, year == 2011), aes(dayofyear, elev.mean)) +
  geom_point(aes(alpha = abund)) +
  facet_wrap(~bb.sp)
```

### Rarefied network analysis (not broken down by phase)
#### Inspect transect counts to set subsampling parameter
```{r, include = FALSE}
### Determine the minimum transect count per site*year to set rarefaction sampling
transects <- net %>%
  dplyr::select(site, year, date) %>%
  unique() %>%
  group_by(site, year) %>%
  summarize(transects = n())

min_transects_per_year <- transects %>%
  group_by(year) %>%
  summarize(min_transects = min(transects))
```

### Tabulate metrics
```{r message=TRUE, warning=TRUE, include=FALSE}
### Auxiliary data
site_BB_aux <- net %>%
  group_by(site, year, date) %>%
  summarize(bb.rich = length(unique(bb.sp)),
            bb.abund = n()) %>%
  group_by(site, year) %>%
  summarize(bb.rich = mean(bb.rich),
            log.bb.abund = log(mean(bb.abund)),
            bb.transects = length(unique(date)))

site_BB_aux.sp <- net %>%
  group_by(site, date, bb.sp) %>% # group by bb.sp*transect (and other variables we want to retain)
  summarize(bb.abund = n()) %>% # get bb.sp*transect abundance
  ungroup %>%
  complete(site, date, bb.sp, fill = list(bb.abund = 0)) %>% # complete implicit absences
  semi_join(net, by = c("site", "date")) %>%
  mutate(year = factor(year(date))) %>%
  group_by(site, year, bb.sp) %>%
  summarize(bb.sp.abund = mean(bb.abund),
            log.bb.abund = log(mean(bb.abund)),
            bb.transects = length(unique(date)))

site_FL_aux <- survey %>%
  mutate(year = factor(year(date))) %>%
  filter(flower.cover > 0) %>%
  group_by(site, year, date) %>%
  summarize(fl.rich = length(unique(plant.sp)),
            fl.abund = sum(flower.cover)) %>%
  group_by(site, year) %>%
  summarize(fl.rich = mean(fl.rich),
            log.fl.abund = log(mean(fl.abund)),
            fl.transects = length(unique(date)))

# Network- and group-level metrics
netmet_boot_2012 <- boot_net(net_2012, n = 9, iter = 40) %>%
  mutate(year = factor(rep("2012", n())))
netmet_boot_2011 <- boot_net(net_2011, n = 7, iter = 40)  %>% # Note that this results in site t5 being dropped, since it had only 4 transects. I think it worth dropping problematic t5 to improve overall quality 
  mutate(year = factor(rep("2011", n())))
# Due to the unevenness of temporal interval of sampling in 2010, I don't think my bootstrapping approach handles  the embuggerance sufficiently.
netmet_boot_2010 <- boot_net(net_2010, n = 3, iter = 40) %>%
  mutate(year = factor(rep("2010", n())))

### Species-level metrics 
spmet_2012 <- boot_net_sp(net_2012, 9, 40) %>%
  mutate(year = factor(rep("2012", n())))
spmet_2011 <- boot_net_sp(net_2011, 7, 40) %>%
  mutate(year = factor(rep("2011", n())))  
spmet_2010 <- boot_net_sp(net_2010, 3, 40) %>%
  mutate(year = factor(rep("2010", n())))

spmet <- bind_rows(spmet_2012, spmet_2011, spmet_2010) %>%
  left_join(site_BB_aux.sp) %>%
  inner_join(site_FL_aux) %>%
  spread(metric, value) %>%
  left_join(site_data) %>%
  ungroup() %>%
  mutate(bb.sp = factor(bb.sp),
         year = factor(year),
         site = factor(site),
         management = factor(management))

spmet_mean <- spmet %>%
  group_by(site, year) %>%
  summarize(resource.range = weighted.mean(resource.range, bb.sp.abund, na.rm = TRUE),
            d = weighted.mean(d, bb.sp.abund, na.rm = TRUE),
            degree = weighted.mean(degree, bb.sp.abund, na.rm = TRUE),
            partner.diversity = weighted.mean(partner.diversity, bb.sp.abund, na.rm = TRUE)) %>%
  #summarize(resource.range = mean(resource.range, na.rm = TRUE)) %>%
  ungroup()

### Merge network metrics and auxiliary data
netmet <- bind_rows(netmet_boot_2012, 
                    netmet_boot_2011,
                    netmet_boot_2010) %>%
  ungroup() %>%
  spread(metric, value) %>%
  left_join(spmet_mean, by = c("site", "year")) %>%
  left_join(site_BB_aux, by = c("site", "year")) %>%
  inner_join(site_FL_aux, by = c("site", "year")) %>% # one site-year is missing from floral survey data
  left_join(site_data, by = "site") %>%
  mutate(year = factor(year, levels = c("2010", "2011", "2012")),
         site = factor(site),
         management = factor(management),
         threshold = factor(case_when(
           elev.mean > 1300 ~ "above",
           elev.mean <= 1300 ~ "below"
           ))
         )
```

### Maybe the answer is not to abandon network analysis, but to include all the variables that confound my target relationship with elevation in a big model, then use variable selection to see what *does* predict network structure. I have massive concurvity, of course, so if the select() feature doesn't deal with that, I might need to opt for a model selection approach. 

#### A source of embuggerance that I have not yet dealt with is that when I bootstrap to equalize transects count, I do not do anything to equalize the temporal (either yday or GDD) interval spanned by the randomly drawn transects. This will, of course, average out as I increase iterations, so I guess the real problem is that the time interval spanned by the full set of transects for each site varies, so no matter how much bootstrapping I do, there will still be potential bias. This seems a fairly insurmountable limitation of the sampling structure of my data, so I will probably resort to just acknowledging it as a caveat of my analysis. 

#### The way I see it, there are two schools of thought that could guide this analysis. (1) If I am only interested in modeling elevational patterns in my response variable, then I should include only elevation and bb.transects in the model. (2) If my goal is to explain the response variable as best I can, then I should throw all my variables into the model, knowing that they may covary with elevation, or that the effects of elevation may be mediated by these other variables. The latter strategy would shed more light on what DOES influence the response variables, but it would obscure pruely elevational patterns. The former would reveal any elevation patterns that might exist, but it would probably not do as good a job of explaining the response variable. Let's try both and see what we learn. Maybe we'll end up turning to SEM in the end if I can figure it out. 

### Elevation-focused modeling
```{r}
ggplot(netmet, aes(elev.mean, C.score.HL,)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~year)

#### Niche overlap
gam_niche.overlap.1 <- gam(niche.overlap.HL ~ 
                             s(year, bs = "re") + 
                             s(bb.transects) + 
                             s(log.bb.abund) +
                             #s(bb.rich) +
                             s(elev.mean, by = year, k = 10),
                           select = TRUE,
                           data = netmet,
                           method = "REML") %>% getViz()

check.gamViz(gam_niche.overlap.1)
concurvity(gam_niche.overlap.1, full = TRUE)
concurvity(gam_niche.overlap.1, full = FALSE)
summary(gam_niche.overlap.1)
print(plot(gam_niche.overlap.1, allTerms = TRUE), pages = 1)

ggplot(netmet, aes(elev.mean, niche.overlap.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

ggplot(netmet, aes(log.bb.abund, niche.overlap.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

ggplot(netmet, aes(bb.rich, niche.overlap.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

#### Niche overlap
gam_C.score.1 <- gam(C.score.HL ~ 
                             s(year, bs = "re") + 
                             s(bb.transects) + 
                             s(log.bb.abund) +
                             #s(bb.rich) +
                             s(elev.mean, by = year, k = 10),
                           select = TRUE,
                           data = netmet,
                           method = "REML") %>% getViz()

check.gamViz(gam_C.score.1)
concurvity(gam_C.score.1, full = TRUE)
concurvity(gam_C.score.1, full = FALSE)
summary(gam_C.score.1)
print(plot(gam_C.score.1, allTerms = TRUE), pages = 1)

ggplot(netmet, aes(elev.mean, C.score.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

ggplot(netmet, aes(log.bb.abund, C.score.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

ggplot(netmet, aes(bb.rich, C.score.HL)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

### NODF
gam_NODF.1 <- gam(weighted.NODF ~ 
                             s(year, bs = "re") + 
                             s(bb.transects) + 
                             s(log.bb.abund) +
                             #s(bb.rich) +
                             s(elev.mean, by = year, k = 10),
                           select = TRUE,
                           data = netmet,
                           method = "REML") %>% getViz()

check.gamViz(gam_NODF.1)
concurvity(gam_NODF.1, full = TRUE)
concurvity(gam_NODF.1, full = FALSE)
summary(gam_NODF.1)
print(plot(gam_NODF.1, allTerms = TRUE), pages = 1)

##### Resource range
gam_mean_rr.1 <- gam(resource.range ~ 
                      s(year, bs = "re") + 
                      s(bb.transects) +
                       s(log.bb.abund) +
                      s(elev.mean, by = year, k = 10),
                    select = TRUE,
                    data = netmet,
                    method = "REML") %>% getViz()

check.gamViz(gam_mean_rr.1)
concurvity(gam_mean_rr.1, full = TRUE)
concurvity(gam_mean_rr.1, full = FALSE)
summary(gam_mean_rr.1)
print(plot(gam_mean_rr.1, allTerms = TRUE), pages = 1)

ggplot(netmet, aes(elev.mean, resource.range)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp", k = 10)) +
  facet_wrap(~year)

ggplot(spmet, aes(elev.mean, resource.range, color = year)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3)) +
  facet_wrap(~bb.sp, scales = "free")

## Species-level resource range
gam_rr.sp_I <- gam(resource.range ~ 
                    s(year, bs = "re") + 
                    #s(site, bs = "re") +
                    #management +
                    s(bb.transects) +
                    s(bb.sp, bs = "re") +
                     s(log.bb.abund, k = 5) +
                    s(elev.mean, by = bb.sp, bs = "tp", k = 5),
                  #s(fl.rich, k = 8) +
                  #s(log.fl.abund, k = 8) +
                  #s(bb.sp.abund, k = 5),
                  select = TRUE,
                  data = spmet,
                  method = "REML") %>% getViz()

check.gamViz(gam_rr.sp_I)
concurvity(gam_rr.sp_I, full = TRUE)
concurvity(gam_rr.sp_I, full = FALSE)
summary(gam_rr.sp_I)
print(plot(gam_rr.sp_I, allTerms = TRUE), pages = 4)


ggplot(spmet, aes(log.bb.abund, resource.range)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~year, scales =  "free")

```

### Let's inspect correlations within our predictors
#### Collinearity among my predictors will be unavoidable, but I can try to mitigate the situation. Bumble bee richness and abundance are almost perfectly correlated, so I definitely don't want to include them both in the same model. Floral abundance and richness are not significantly correlated (interestingly), but each is correlated with both bumble bee richness and bumble bee abundance. So, I think the goal is to pick the combination that minimizes collinearity. The weakest correlation between a bumble bee variable and a floral variable is between bumble bee richness and floral abundance, though the correlation is still pretty strong. Thus, I think an argument can be made for including only bumble bee richness and floral abundance in my models. 
```{r message=FALSE}
predictors <- netmet %>%
  select(elev.mean, bb.rich, log.bb.abund, 
         fl.rich, log.fl.abund, bb.transects, year)

ggpairs(predictors)

ggplot(predictors, aes(log.fl.abund, bb.rich)) +
  geom_point() +
  facet_wrap(~year)

ggplot(predictors, aes(log.fl.abund, log.bb.abund)) +
  geom_point() +
  facet_wrap(~year)

ggplot(predictors, aes(fl.rich, log.bb.abund)) +
  geom_point() +
  facet_wrap(~year)

ggplot(predictors, aes(fl.rich, bb.rich)) +
  geom_point() +
  facet_wrap(~year)
```

### Response-focused modeling
```{r}
#### Niche overlap
gam_niche.overlap.2 <- gam(niche.overlap.HL ~ 
                             s(year, bs = "re") + 
                             #s(management, bs = "re") +
                             s(bb.transects) + 
                             s(elev.mean, by = year, k = 10) +
                             s(bb.rich, k = 5) + 
                             s(log.fl.abund, k = 5),  # no effect
                           select = TRUE,
                           data = netmet,
                           method = "REML") %>% getViz()

check.gamViz(gam_niche.overlap.2)
concurvity(gam_niche.overlap.2, full = TRUE)
concurvity(gam_niche.overlap.2, full = FALSE)
summary(gam_niche.overlap.2)
print(plot(gam_niche.overlap.2, allTerms = TRUE), pages = 1)

ggplot(netmet, aes(elev.mean, niche.overlap.HL)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~year)

ggplot(netmet, aes(bb.transects, niche.overlap.HL)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year, scales = "free_x")

ggplot(netmet, aes(elev.mean, bb.transects)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~year)

#### Resource range
gam_mean_rr.2 <- gam(resource.range ~ 
                      s(year, bs = "re") + 
                      #s(management, bs = "re") +
                      s(bb.transects) +
                      s(elev.mean, by = year, k = 10) +
                      #s(bb.rich, k = 5) +
                       s(fl.rich, k = 5) +
                       s(log.bb.abund, k = 5),
                     # s(log.fl.abund, k = 5),
                    select = TRUE,
                    data = netmet,
                    method = "REML") %>% getViz()

check.gamViz(gam_mean_rr.2)
concurvity(gam_mean_rr.2, full = TRUE)
concurvity(gam_mean_rr.2, full = FALSE)
summary(gam_mean_rr.2)
print(plot(gam_mean_rr.2, allTerms = TRUE), pages = 1)

ggplot(netmet, aes(bb.rich, resource.range)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year)

ggplot(netmet, aes(log.bb.abund, resource.range)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year)

ggplot(netmet, aes(log.fl.abund, resource.range)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year)

ggplot(netmet, aes(fl.rich, resource.range)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year)
```

### But shouldn't I be using the abundance data from the floral survey instead of the marginal totals? Yes. But no. In many cases, the species quantified during floral surveying do not include all of the species observed in the network. In those cases, I would have to either make up abundance data or drop floral species from the network, and both of those seem like bad ideas. Perhaps this is an argument for not using d'? If marginal totals are bad measures of abundance -- and I believe they are -- then maybe we need to either abandon the idea of analyzing specialization or opt for a simpler specialization metric, like PDI
```{r}
test <- net %>%
      # semi_join(t_filter) %>%
      # dplyr::select(site, date, year) %>%
      # unique() %>%
      # group_by(site, year) %>%
      # sample_n(n) %>%
      # left_join(net) %>%
      group_by(site, year, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
      summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
      unite(webID, c(site, year), sep = "_") %>%
      ungroup() %>%
      dplyr::select(higher = bb.sp, lower = plant.sp, webID, freq) %>% # rename columns to match bipartite's expectations
      data.frame() 

survey_sum <- survey %>%
  group_by(site, date, plant.sp) %>%
  summarize(raw.abund = sum(flower.cover)) %>%
  group_by(site, date) %>%
  mutate(prop.abund = raw.abund/sum(raw.abund),
         year = year(date)) %>%
  group_by(site, year, plant.sp) %>%
  summarize(mean.prop.abund = mean(prop.abund)) %>%
  unite(webID, c(site, year), sep = "_") %>%
  rename(lower = plant.sp) %>%
  semi_join(test)

webs <- test %>% # convert to data frame
      frame2webs() 

h1_2010 <- specieslevel(webs[[1]], level = "higher", index = "d", low.abun = filter(survey_sum, webID == "h1_2010")$mean.prop.abund) 

h1_2011 <- specieslevel(webs[[2]], level = "higher", index = "d", low.abun = filter(survey_sum, webID == "h1_2011")$mean.prop.abund) 

h1_2012 <- specieslevel(webs[[2]], level = "higher", index = "d", low.abun = filter(survey_sum, webID == "h1_2012")$mean.prop.abund) 

%>% # convert to to bipartite web
      map(specieslevel, level = "higher", index = "d") %>%
      map(rownames_to_column) %>%
      map(as_tibble) %>%
      bind_rows(.id = "site_year") %>% # Collapse list into big data frame
      rename(bb.sp = rowname)

ggplot(test, aes(bb.sp, d)) +
  geom_boxplot()
```

### Since we clearly have structured collinearity in our preditors, i.e. elevation shapes abundance and diversity which shape network structure, perhaps SEM could be appropriate? The main question is whether it can handle the potentially complex (nonlinear) relationships between elevation and diversity/abundance, and whether it can handle the hierarchical structure of my data.
```{r}
# Create scales variables; this is important since SEM is based on covariance (right?)
# For starters, let's just try to model niche.overlap
netmet.scaled <- netmet %>%
  select(site, year, niche.overlap.HL, elev.mean, 
         fl.rich, bb.rich, log.fl.abund, log.bb.abund) %>%
  mutate(elev.mean.2 = elev.mean^2,
         elev.mean.3 = elev.mean^3) %>%
  # mutate_at(c("niche.overlap.HL", "elev.mean", "elev.mean.2", "elev.mean.3", 
  #        "fl.rich", "bb.rich", "log.fl.abund", "log.bb.abund"), ~(scale(.) %>% as.vector)) %>% # I did not know you could put pipes inside a mutate call -- good to know: https://stackoverflow.com/questions/15215457/standardize-data-columns-in-r
  na.omit()

# Pairs plot to determine best model form
predictors.scaled <- netmet.scaled %>%
  select(elev.mean, elev.mean.2, elev.mean.3, bb.rich, 
         log.bb.abund, fl.rich, log.fl.abund, niche.overlap.HL)

ggpairs(predictors.scaled)

# Diversity and abundance metrics clearly have a quadratic relationship with elevation

# Call models
# To avoid figuring out how to handle year and site as random effects, let's start with separate year models
netmet.scaled.2010 <- filter(netmet.scaled, year == 2010)
netmet.scaled.2011 <- filter(netmet.scaled, year == 2011)
netmet.scaled.2012 <- filter(netmet.scaled, year == 2012)

mod_niche.overlap.2010 <- psem(
  lm(niche.overlap.HL ~ elev.mean + log.fl.abund + bb.rich, 
     netmet.scaled.2010),
  lm(log.fl.abund ~ elev.mean, 
     netmet.scaled.2010),
  lm(bb.rich ~ elev.mean, 
     netmet.scaled.2010)
)

summary(mod_niche.overlap.2010)
plot(mod_niche.overlap.2010)

mod_niche.overlap.2011 <- psem(
  lm(niche.overlap.HL ~ elev.mean + log.fl.abund + bb.rich, 
     netmet.scaled.2011),
  lm(log.fl.abund ~ elev.mean, 
     netmet.scaled.2011),
  lm(bb.rich ~ elev.mean, 
     netmet.scaled.2011)
)

summary(mod_niche.overlap.2011)
plot(mod_niche.overlap.2011)

mod_niche.overlap.2012 <- psem(
  lm(niche.overlap.HL ~ elev.mean + log.fl.abund + bb.rich, 
     netmet.scaled.2012),
  lm(log.fl.abund ~ elev.mean, 
     netmet.scaled.2012))
)

summary(mod_niche.overlap.2012)
plot(mod_niche.overlap.2012)
```

## Threshold-based network analysis: do network properties differ meaningfully above and below the threshold (~1300m) evident in my abundance and beta-diversity analyses?
```{r}

```