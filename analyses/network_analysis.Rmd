---
title: "network_analysis"
output: html_document
---

### Prepare environment
```{r setup, include=FALSE}
library(bipartite)
library(mgcv)
library(mgcViz)
library(tidyverse)
library(lubridate)
```

### Define functions
#### Bootstrapped network analysis: *boot_net* function bootstraps networks by iteratively subsampling more frequently sampled networks to match the transect count of the least frequently sampled one
```{r, include=FALSE}
#####################################
######## species level ##############
#####################################
boot_net_sp <- function(net, n, iter) {
  
  out <- data.frame()
  
  t_filter <- net %>%
    dplyr::select(site, date, year) %>%
    unique() %>%
    group_by(site, year) %>%
    mutate(transects = n()) %>%
    filter(transects >= n)
  
  for(i in 1:iter) {
    temp <- net %>%
      semi_join(t_filter) %>%
      dplyr::select(site, date, year) %>%
      unique() %>%
      group_by(site, year) %>%
      sample_n(n) %>%
      left_join(net) %>%
      group_by(site, year, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
      summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
      unite(webID, c(site, year), sep = "_") %>%
      #group_by(site_year) %>%
      #filter(length(unique(bb.sp)) > 1 & length(unique(plant.sp)) > 1) %>%
      #ungroup() %>%
      #filter(freq > 1) %>% # remove singletons
      dplyr::select(higher = bb.sp, lower = plant.sp, webID, freq) %>% # rename columns to match bipartite's expectations
      data.frame() %>% # convert to data frame
      frame2webs() %>% # convert to to bipartite web
      map(specieslevel, level = "higher", index = "d") %>%
      map(rownames_to_column) %>%
      map(as_tibble) %>%
      bind_rows(.id = "site_year") %>% # Collapse list into big data frame
      rename(sp = rowname) %>%
      mutate(iteration = rep(i, n()))
    
    out <- bind_rows(out, temp)
  } 
  out <- out %>%
    gather(metric, value, -c(sp, site_year, iteration)) %>% # get mean value across iterations for each metric
    group_by(sp, site_year, metric) %>%
    summarize(value = mean(value)) %>%
    separate(site_year, c("site", "year"), sep = "_") %>%
    left_join(site_data) 
  # %>%
  #   left_join(bb_traits, by = c("sp" = "bb.sp"))
}

#####################################
######## network level ##############
#####################################
boot_net <- function(net, n, iter) {
  
  out <- data.frame()
  
  for(i in 1:iter) {
    temp <- net %>%
      dplyr::select(site, date) %>%
      unique() %>%
      group_by(site) %>%
      sample_n(n) %>%
      left_join(net) %>%
      group_by(site, bb.sp, plant.sp) %>% # group by site, date, bee species, plant species
      summarize(freq = n()) %>% # calculate interaction frequency per species pair within each site
      group_by(site) %>%
      filter(length(unique(bb.sp)) > 1 & length(unique(plant.sp)) > 1) %>%
      ungroup() %>%
      dplyr::select(higher = bb.sp, lower = plant.sp, webID = site, freq) %>% # rename columns to match bipartite's expectations
      data.frame() %>% # convert to data frame
      frame2webs() %>% # convert to to bipartite web
      map(networklevel, level = "higher", weighted = TRUE, 
          index = c("weighted NODF", "niche overlap", 
                    "C score", "generality", "web asymmetry", 
                    "weighted connectance")) %>% # We probably care mainly about the BB level of the network
      data.frame() %>%
      t() %>%
      data.frame() %>%
      rownames_to_column() %>%
      dplyr::select(site = rowname, everything()) %>%
      as_tibble() %>%
      mutate(iteration = rep(i, n()))
    
    out <- bind_rows(out, temp)
  } 
  out <- out  %>%
      gather(metric, value, -c(site, iteration)) %>% # get mean value across iterations for each metric
      group_by(site, metric) %>%
      summarize(value = mean(value)) %>%
      left_join(site_data)
}
```

### Load site data
```{r, include=FALSE}
site_data <- read_csv("../processed_data/site_data.csv") %>%
  dplyr::select(-c(slope.calc, slope.est, elev.min, elev.max, temp.mean)) %>% # drop these variables
  mutate(elev.class = factor(elev.class, levels = c("oben", "mitte", "unten")),
         elev.class2 = factor(elev.class2, levels = c("high", "mid", "low"))) # turn elav.class into an ordered factor
```

### Climate data
```{r, include=FALSE}
gdd <- read_csv("../processed_data/climate.csv") %>%
  mutate(year = factor(year)) %>%
  dplyr::select(site, date, gdd.cum)
```

### Load network and survey data
```{r, include=FALSE}
net <- read_csv("../processed_data/network.csv") %>%
  unite(site.year, site, year, sep = "_", remove = FALSE) %>% # create site.year field that can later be split back up
  mutate(year = factor(year)) %>% # convert year to factor
  left_join(site_data, by = "site") %>%
  left_join(gdd, by = c("site", "date")) %>%
  ungroup() %>%
  arrange(site, date)

# Yearly subsets
net_2012 <- filter(net, year == "2012")
net_2011 <- filter(net, year == "2011")
net_2010 <- filter(net, year == "2010")

### Per-transect BB abundance: species-level
bb_abund_sp <- net %>%
  dplyr::select(site, date, bb.sp) %>%
  group_by(site, date, bb.sp) %>% # group by bb.sp*transect (and other variables we want to retain)
  summarize(bb.abund = n()) %>% # get bb.sp*transect abundance
  ungroup %>%
  complete(site, date, bb.sp, fill = list(bb.abund = 0)) %>% # complete implicit absences
  semi_join(net, by = c("site", "date")) %>%
  mutate(year = factor(year(date))) %>%
  mutate(yday = yday(date),
         sp = factor(bb.sp),
         site = factor(site)) %>%
  group_by(site, year, sp) %>%
  summarize(bb.total.abund = sum(bb.abund))
```

### Rarefied network analysis (not broken down by phase)
#### Inspect transect counts to set subsampling parameter
```{r, include = FALSE}
### Determine the minimum transect count per site*year to set rarefaction sampling
transects <- net %>%
  dplyr::select(site, year, date) %>%
  unique() %>%
  group_by(site, year) %>%
  summarize(transects = n())

min_transects_per_year <- transects %>%
  group_by(year) %>%
  summarize(min_transects = min(transects))
```


### Network- and group-level metric tables
```{r}
netmet_boot_2012 <- boot_net(net_2012, n = 9, iter = 40) %>%
  mutate(year = factor(rep("2012", n())))
netmet_boot_2011 <- boot_net(net_2011, n = 4, iter = 40)  %>%
  mutate(year = factor(rep("2011", n())))
netmet_boot_2010 <- boot_net(net_2010, n = 3, iter = 40) %>%
  mutate(year = factor(rep("2010", n())))

netmet <- bind_rows(netmet_boot_2012, 
                    netmet_boot_2011, 
                    netmet_boot_2010) %>%
  ungroup() %>%
  mutate(metric = factor(metric, levels = c("weighted.NODF",
                                            "niche.overlap.HL", 
                                            "C.score.HL",
                                            "generality.HL",
                                            "web.asymmetry",
                                            "weighted.connectance"))) %>%
  mutate(year = factor(year),
         site = factor(site))
```

#### Species-level metric tables
```{r, message=FALSE}
### Species level
#### BBs
spmet_2012 <- boot_net_sp(net_2012, 9, 40) %>%
  mutate(year = factor(rep("2012", n())))
spmet_2011 <- boot_net_sp(net_2011, 4, 40) %>%
  mutate(year = factor(rep("2011", n())))  
spmet_2010 <- boot_net_sp(net_2010, 3, 40) %>%
  mutate(year = factor(rep("2010", n())))

spmet <- bind_rows(spmet_2012, spmet_2011, spmet_2010) %>%
  left_join(bb_abund_sp) %>%
  mutate(sp = factor(sp),
         management = factor(management),
         site = factor(site))

ggplot(filter(spmet, bb.total.abund >= 20 & sp %in% c("bss", "pasc", "prat", "wurf", "soro")), aes(elev.mean, value, color = year)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  facet_wrap(~sp, scales = "free")

ggplot(filter(spmet, bb.total.abund >= 20), aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  facet_wrap(~year)

specialization_GAM.2010 <- bam(value ~ 
                            s(elev.mean, by = sp) +
                            #s(bb.total.abund, by = sp) +
                            s(site, bs = "re") +
                            s(sp, bs = "re"),
                   data = filter(spmet, year == 2010),
                   discrete = TRUE,
                   select = TRUE,
                   method = "fREML") %>% getViz()

check.gamViz(specialization_GAM.2010)
specialization_GAM.2010.sum <- summary(specialization_GAM.2010)
print(plot(specialization_GAM.2010, allTerms = TRUE), pages = 1)


spmet_mean <- spmet %>%
  group_by(site, year, elev.mean, metric) %>%
  summarize(value = weighted.mean(value, bb.total.abund)) %>%
  ungroup() 

ggplot(spmet_mean, aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~year)


```



### Plot network analysis
```{r}
#### Network level
##### niche overlap
ggplot(filter(netmet, metric == "niche.overlap.HL"), aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x)) +
  #geom_smooth() +
  xlab("Elevation") +
  ylab("Niche overlap") +
  facet_wrap(~year) +
  theme_light(16)

gam_niche.overlap <- gamV(value ~ year + s(site, bs = "re") +
                            s(elev.mean, by = year, k = 10, bs = "tp", m = 2), 
                         data = filter(netmet, metric == "niche.overlap.HL"),
                         method = "REML")

gam_niche.overlap2 <- gamV(value ~ year + s(site, bs = "re") +
                            s(elev.mean, k = 10, bs = "tp", m = 2), 
                         data = filter(netmet, metric == "niche.overlap.HL"),
                         method = "REML")

AIC(gam_niche.overlap, gam_niche.overlap2)

check.gamViz(gam_niche.overlap)
summary(gam_niche.overlap)
print(plot(gam_niche.overlap, allTerms = TRUE), pages = 1)

##### C.score
ggplot(filter(netmet, metric == "C.score.HL"), aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x)) +
  xlab("Elevation") +
  ylab("C score") +
  facet_wrap(~year) +
  theme_light(16)

gam_cscore <- gamV(value ~ year + s(site, bs = "re") + 
                     s(elev.mean, bs = "tp", k = 10, m = 2), 
                  data = filter(netmet, metric == "C.score.HL"),
                  #family = "scat",
                  method = "REML")

check.gamViz(gam_cscore)
summary(gam_cscore)
print(plot(gam_cscore, allTerms = TRUE), pages = 1)

#####################################################################################3

#### Per species values
ggplot(filter(spmet_2012_BB,
              sp %in% c("bss", "hort", "pasc", "prat", "soro", "wurf") & metric == "d"), 
       aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 10), color = "black", linetype = "dashed", size = 0.75) +
  facet_wrap(~sp, scales = "free")

ggplot(filter(spmet_2011_BB,
              sp %in% c("bss", "hort", "pasc", "prat", "soro", "wurf") & metric == "d"), 
       aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 10), color = "black", linetype = "dashed", size = 0.75) +
  facet_wrap(~sp, scales = "free")

ggplot(filter(spmet_2010_BB,
              sp %in% c("bss", "hort", "pasc", "prat", "soro", "wurf") & metric == "d"), 
       aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 10), color = "black", linetype = "dashed", size = 0.75) +
  facet_wrap(~sp, scales = "free")

#### Community mean d
##### BB
ggplot(filter(spmet_mean_BB, metric == "d"), aes(elev.mean, value)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 10)) +
  xlab("Elevation") +
  ylab("Community mean d'") +
  facet_wrap(~year) +
  theme_light(16)

gam_d1 <- gamV(value ~ year + 
                 s(elev.mean, k = 8, bs = "tp", by = year, m = 1), 
             data = filter(spmet_mean_BB, metric == "d"),
             method = "REML")

check.gamViz(gam_d1)
summary(gam_d1)
plot(gam_d1, allTerms = TRUE) 

summary(lm(value ~ elev.mean, data =  filter(spmet_mean_BB, metric == "d" & year == 2012)))
plot(lm(value ~ elev.mean, data =  filter(spmet_mean_BB, metric == "d" & year == 2012)))
```

